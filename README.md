# Quick Start and Basic Concept ( Please skip the code)
- [Mistral Cookbook](https://github.com/mistralai/cookbook)
- [1hr Talk Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g)
- [Let's reproduce GPT-2 (124M)](https://www.youtube.com/watch?v=l8pRSuU81PU)
- [OpenAi API Reference](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)
- [RAG From Scratch](https://www.youtube.com/watch?v=wd7TZ4w1mSw&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x)
- [What's next for AI agentic workflows ft. Andrew Ng of AI Fund](https://www.youtube.com/watch?v=sal78ACtGTc)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/en/perf_train_gpu_one#mixture-of-experts)
- [What We‚Äôve Learned From A Year of Building with LLMs](https://applied-llms.org)
- [LLM101n: Let's build a Storyteller](https://github.com/karpathy/LLM101n)


# Short Tutorials
## Dataset
- [FineWeb](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1)
- [HellaSwag](https://rowanzellers.com/hellaswag/)
- [üíæ LLM Datasets](https://github.com/mlabonne/llm-datasets)
- 
  
## Promopt Engineering
- [Promopt Engineering with Llama 2](https://learn.deeplearning.ai/courses/prompt-engineering-with-llama-2/lesson/1/introduction)
- [GenAI Handbook](https://genai-handbook.github.io)
- [LLM from Scratch](https://github.com/rasbt/LLMs-from-scratch)
- [Prompt Survey](https://trigaten.github.io/Prompt_Survey_Site/)
- [Memory of Thought](https://arxiv.org/pdf/2305.05181)
- [Chain of Thought](https://arxiv.org/abs/2201.11903)
- 
## RAG
- [RAG From Scratch](https://www.youtube.com/watch?v=wd7TZ4w1mSw&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x)
- [Preprocessing Unstructured Data for LLM Applications](https://learn.deeplearning.ai/courses/preprocessing-unstructured-data-for-llm-applications/lesson/1/introduction)
- [Building Applications with Vector Databases](https://learn.deeplearning.ai/courses/building-applications-vector-databases/lesson/1/introduction)
- [advanced retrieval for ai](https://learn.deeplearning.ai/courses/advanced-retrieval-for-ai/lesson/1/introduction)
- [Large Language Models with Semantic Search](https://learn.deeplearning.ai/courses/large-language-models-semantic-search/lesson/1/introduction)
- [Building and Evaluating Advanced RAG](https://learn.deeplearning.ai/courses/building-evaluating-advanced-rag/lesson/1/introduction)
- [Vector Databases: from Embeddings to Applications](https://learn.deeplearning.ai/courses/vector-databases-embeddings-applications/lesson/1/introduction)
- [Understanding and Applying Text Embeddings](https://learn.deeplearning.ai/courses/google-cloud-vertex-ai/lesson/1/introduction)

## Finetuning
### Data Preparation
- [LIMA: Less Is More for Alignment](https://arxiv.org/abs/2305.11206)
- [LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report](https://arxiv.org/abs/2405.00732)
  
### Parameter Efficient Fine Tuning
- [P-Tuning](https://aclanthology.org/2022.acl-short.8.pdf)
- [P-Tuning v2](https://arxiv.org/abs/2110.07602)
- [LoRA](https://arxiv.org/pdf/2106.09685)
- [IA3](https://arxiv.org/pdf/2205.05638)
- [Finetuning Large Language Models](https://learn.deeplearning.ai/courses/finetuning-large-language-models/lesson/1/introduction)
- [Evaluating and Debugging Generative AI](https://learn.deeplearning.ai/courses/evaluating-debugging-generative-ai/lesson/1/introduction)
- [Efficiently Serving LLMs](https://www.deeplearning.ai/short-courses/efficiently-serving-llms/)
- [parameter-efficient-fine-tuning](https://medium.com/@abonia/llm-series-parameter-efficient-fine-tuning-e9839fae44ac)
- [PEFT](https://arxiv.org/pdf/2312.12148)
- [SFT Examples with QLoRA](https://medium.com/@shitalnandre108/fine-tuning-llama-2-large-language-model-with-custom-datasets-using-google-colab-a-comprehensive-a9d68faf3bc9)
- [Predibase: Efficiently Server Multiple LoRA Land Adapter.ipynb](https://colab.research.google.com/drive/1twBQZ_9PfoWhCGYL8QQEx_rmcvmTDOOA?usp=sharing#scrollTo=6qP9g-shUqzy)
- [Finetune examples](https://colab.research.google.com/drive/1rxg7fJfGYZUgG7QPa3EavXzoyY5QPE9U?usp=sharing)
- [Lora Land](https://predibase.com/lora-land)

### RLHF
- [Reinforcement Learning From Human Feedback](https://learn.deeplearning.ai/courses/reinforcement-learning-from-human-feedback/lesson/1/introduction)

## Deployment
### Quantilization
- [Quantization Overview](https://medium.com/snowflake/snowflake-arctic-cookbook-series-arctics-approach-to-data-b81a8a0958bd)
- [Quantization Survey](https://arxiv.org/pdf/2103.13630)
- [QAT & PTQ](https://iprathore71.medium.com/diving-deeper-into-quantization-realm-9c73e3172a3c)

### LLMOps Architecture
- [Architectures for LLM applications](https://a16z.com/emerging-architectures-for-llm-applications/)
- [E2E Framework](https://www.comet.com/site/blog/an-end-to-end-framework-for-production-ready-llm-systems-by-building-your-llm-twin/)
- [ML ops](https://github.com/visenger/awesome-mlops)
  
### Orchestration Tools
- [DIFY](https://github.com/langgenius/dify)
- [LangChain](https://www.langchain.com)
- [Pydantic](https://docs.pydantic.dev/latest/why/)
  
## Agent
- [Functions, Tools and Agents with LangChain](https://learn.deeplearning.ai/courses/functions-tools-agents-langchain/lesson/1/introduction)
- [LLM Agent](https://medium.com/the-modern-scientist/a-complete-guide-to-llms-based-autonomous-agents-part-i-69515c016792)
- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/)
- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/))

## Diffusion
- [Introduction to Image Generation](https://www.cloudskillsboost.google/paths/183/course_templates/541?utm_source=cgc&utm_medium=blog&utm_campaign=giftoflearning2023)
- [How Diffusion Models Work](https://learn.deeplearning.ai/courses/diffusion-models/lesson/1/introduction)

## Multimodal
- [Multimodal Algorithmic Reasoning Workshop](https://www.youtube.com/watch?v=LooLbLs3O_Y)
- [LLAVA](https://chunyuan.li)
- 
## Hallucination Detection
- [awesome-hallucination-detection](https://github.com/EdinburghNLP/awesome-hallucination-detection?tab=readme-ov-file#measuring-hallucinations-in-llms)
- 



# Comprehensive Tutorial
- [microsoft/generative-ai-for-beginners](https://github.com/microsoft/generative-ai-for-beginners)
- [12 days of no-cost training to learn generative AI this December](https://cloud.google.com/blog/topics/training-certifications/12-days-of-no-cost-generative-ai-training)
- [Large Language Models, Part I](https://www.youtube.com/watch?v=2yjzZfDQxy8)
- [Large Language Models, Part II](https://www.youtube.com/watch?v=mxERaO8FXHc)
- [Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE)
- [Stanford CS25](https://web.stanford.edu/class/cs25/)
- [LLM Course](https://github.com/mlabonne/llm-course)
- [Introduction to LangGraph](https://academy.langchain.com/courses/intro-to-langgraph)
- [Hands-On-Large-Language-Models](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models)
- [Awesome LLM Apps](https://github.com/Shubhamsaboo/awesome-llm-apps)
- [Awesome LLM Strawberry (OpenAI o1)](https://github.com/hijkzzz/Awesome-LLM-Strawberry)
- [Reasoning](https://github.com/hijkzzz/Awesome-LLM-Strawberry)


  
# Papers
- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
- [SFT](https://cameronrwolfe.substack.com/p/understanding-and-using-supervised)
- [RLHF](https://arxiv.org/pdf/2203.02155)
- [DPO](https://arxiv.org/pdf/2305.18290)
- [ORPO](https://arxiv.org/abs/2403.07691)
- [RLAIF](https://arxiv.org/abs/2309.00267)
- [LoRA Paper](https://arxiv.org/pdf/2106.09685)
- [LoRA YouTube](https://www.youtube.com/watch?v=PXWYUTMt-AU)
- [LoRA Github](https://github.com/hkproj/pytorch-lora)
- [QLoRA](https://arxiv.org/pdf/2305.14314)
- [Gemini: A Family of Highly Capable Multimodal Models](https://arxiv.org/pdf/2312.11805)
- [GPT-4 Technical Report](https://cdn.openai.com/papers/gpt-4.pdf)
- [ReFT](https://arxiv.org/pdf/2404.03592)
- [Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment](https://arxiv.org/pdf/2312.12148)
- [Lora Land](https://arxiv.org/pdf/2405.00732)
- [AI Scientist](https://arxiv.org/pdf/2408.06292)

# Open Source Model Review
## Llama
- [Llama 2 Paper](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)

## GPT
- [GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

## SnowFlake Arctic
- [SnowFlake Artic Github] (https://github.com/Snowflake-Labs/snowflake-arctic)
  
## Reference
- [MOE review](https://huggingface.co/blog/moe)
- [DeepSpeed](https://github.com/microsoft/DeepSpeed/)
- [Zero-2](https://arxiv.org/abs/1910.02054)
- [MOE](https://arxiv.org/pdf/1701.06538)
- [Deep Speed MOE](https://www.microsoft.com/en-us/research/blog/deepspeed-advancing-moe-inference-and-training-to-power-next-generation-ai-scale/)
- [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/pdf/2101.03961)
- [GlaM](https://arxiv.org/abs/2112.06905)
- [GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding](https://arxiv.org/abs/2006.16668)
- [Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models](https://arxiv.org/pdf/2305.14705)
- [AdamW](https://paperswithcode.com/method/adamw)
  
# Other Useful Resources
- [awesome-generative-ai-guide](https://github.com/aishwaryanr/awesome-generative-ai-guide?tab=readme-ov-file)
- [Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)
- [AI Collection](https://github.com/ai-collection/ai-collection)
- [Awesome-LLMOps](https://github.com/tensorchord/Awesome-LLMOps)
- [Awesome-LLM-Inference](https://github.com/DefTruth/Awesome-LLM-Inference)
- [Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)
- [Awesome Generative AI ](https://github.com/filipecalegario/awesome-generative-ai)
- [LLM for autonomous driving](https://github.com/Thinklab-SJTU/Awesome-LLM4AD)
- [Awesome LLM agents](https://github.com/kaushikb11/awesome-llm-agents)
- [Awesome Generative AI](https://github.com/steven2358/awesome-generative-ai)

# Popular Github
- [RD Agent](https://github.com/microsoft/RD-Agent)
- [DsPy](https://github.com/stanfordnlp/dspy)
- [Auto-GPT](https://github.com/Significant-Gravitas/AutoGPT)
- [Auto/gen](https://microsoft.github.io/autogen/)
- [MetaGPT](https://github.com/geekan/MetaGPT)
- [MeMGPT](https://memgpt.readme.io/docs/index)
- [Open Devin](https://github.com/OpenDevin/OpenDevin)
- [Devika](https://github.com/stitionai/devika)
- [AIOS](https://github.com/agiresearch/AIOS)
- [Agent OPS](https://github.com/AgentOps-AI/agentops)
- [FinGPT](https://github.com/AI4Finance-Foundation/FinGPT)
- [DeepSeek](https://www.deepseek.com)
- [GPT Computer Assistant](https://github.com/onuratakan/gpt-computer-assistant?tab=readme-ov-file)
- [LitGPT](https://github.com/Lightning-AI/litgpt)
- [Open Interpreter](https://github.com/OpenInterpreter/open-interpreter)
- [AI tools](https://huyenchip.com/llama-police)
- [Contrastive Learning](https://github.com/KingGugu/DA-CL-4Rec)
- [Lil Log](https://lilianweng.github.io/)
- [O1 Engineer](https://github.com/Doriandarko/o1-engineer)
- [LLM Course] (https://github.com/mlabonne/llm-course)
- [Awesome LLM Reasoning] (https://github.com/atfortes/Awesome-LLM-Reasoning)
- [üó£Ô∏è Large Language Model Course](https://github.com/mlabonne/llm-course)




